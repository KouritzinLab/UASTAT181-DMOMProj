{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "x3hRcLO0U68V",
        "RRfgzt3lzKYd"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KumarRishabh/Discrete-MOM/blob/main/STAT_181_Project_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions to run the programs\n",
        "Hello, STAT 181-ers! I hope you enjoyed the STAT 181 course and are ready to play with some models deployed on a financial time series data. This is a jupyter-notebook in which the code is written in python. The regions with the python code are called cells. To execute the piece of code, you can take the following paths: \n",
        "\n",
        "1. Hover over the cells and you will see a play button like such (⏵) on the left hand side of the cell. Clicking the play button will execute the cell. \n",
        "2. Press Cmd + Enter (if on OS X) OR Press Ctrl + Enter (in Linux or Windows) \n",
        "3. Go to Runtime > Run Selection to run a particular cell. \n",
        "\n",
        "***NOTE*** Please note that every cell before the question needs to be executed before answering the question cell. \n",
        "\n",
        "## GOAL OF THE PROJECT\n",
        "Once STAT 181 is over I'm pretty sure that you will be bored. Don't worry though! We have tons of data to get handsy with. Might as well make some money. That's slightly better than being bored, right? Let's investigate trading Bitcoin. \n",
        "\n",
        "The Bitcoin price data has been split into two parts: \n",
        "\n",
        "1. Training: Starts from `2018-9-1` and goes to `2022-9-1`\n",
        "2. Testing: Starts from `2022-9-1` and goes to `2023-9-1`\n",
        "\n",
        "The parameters of the model would be trained using the training data, which would be then used on the unseen test data through executing a strategy, from which some profit/loss would be incurred. Try to make a model which produces the maximum profit over the test set. The questions have been provided to guide you along the way. \n",
        "\n",
        "There are couple of different things that you will encounter while you answer the questions in this assignment: \n",
        "\n",
        "1. Setups\n",
        "2. Questions\n",
        "\n",
        "Setups are designed in a way so that you can manipulate the variables according to your liking. Giving some input to the setup part is important, and skipping it is not advised.\n",
        "## Mode of Submission\n",
        "Please print the notebook either by:\n",
        "1. Going to File > Print\n",
        "2. Press Ctrl + P (Linux or Windows) or Cmd + P (Mac)\n",
        "\n",
        "Type in your answers by clicking twice and editing the text cells. Upload the PDF of the final document by following the steps above to print it and upload it on ***Assign2***. \n",
        "\n",
        "***(For the Advanced $\\LaTeX$ Geek!)*** You can directly convert the colab notebook to a $\\TeX$ file. To do so, follow these steps: \n",
        "\n",
        "1. Go to File > Download > Download .ipynb\n",
        "2. Store it to a `path = <path-to-the-notebook>`\n",
        "3. On your terminal (You can use WSL if in windows) type `jupyter nbconvert path --to latex`."
      ],
      "metadata": {
        "id": "FISl7PSVAR9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Markov Observation Model\n",
        "The following is the python code for Markov Observation Model.\n",
        "\n",
        "In this algorithm, X's are the hidden states of bitcoin. \n",
        "\n",
        "Y's are the observation sequence of the bitcoin prices. The data can be found on [Bitcoin USD, Yahoo Finance Data](\n",
        "https://ca.finance.yahoo.com/quote/BTC-USD?p=BTC-USD&.tsrc=fin-srch) under the historical data section. "
      ],
      "metadata": {
        "id": "vEgYr8jFOucF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTING ESSENTIAL LIBRARIES\n",
        "Click on the play button to run the code below to import the essential libraries and setup the training and test dates, according to the time intervals discussed before. \n"
      ],
      "metadata": {
        "id": "mvM3W6hBV_LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing essential libraries\n",
        "!pip install --user yahoofinance\n",
        "!pip install --user jupyter-dash\n",
        "import yfinance as yf\n",
        "import sys\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as pdr\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.preprocessing import normalize\n",
        "from tabulate import tabulate\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# %matplotlib notebook\n",
        "np.random.seed(10)"
      ],
      "metadata": {
        "id": "xX2D29FWSqkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A section bitcoin price data from yahoo finance:\n",
        "# This section of the code is for initialization\n",
        "\n",
        "train_start = datetime(2018, 9, 1)\n",
        "train_end = datetime(2022, 9, 1)\n",
        "test_start = datetime(2022, 9, 1)\n",
        "test_end = datetime(2023, 9, 1) \n",
        "\n",
        "## Importing the Google finance\n",
        "\n",
        "bitcoin = yf.Ticker(\"BTC-USD\")\n",
        "dat = bitcoin.history(start = train_start, end = test_end, interval = \"1d\")\n",
        "train_dat = bitcoin.history(start = train_start, end = train_end, interval = \"1d\")\n",
        "test_dat = bitcoin.history(start = test_start, end = test_end, interval = \"1d\")\n",
        "print(train_dat.shape)"
      ],
      "metadata": {
        "id": "seQfMtW-AbbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0fpkPthGCAnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. Note prices are the observed Markov Chain \n",
        " \n",
        "a) What could be the hidden states model? \n",
        "\n",
        "b) How many hidden states would you want to use? What does each of the hidden states represent?\n",
        " \n",
        "*Hint: Increasing the number of hidden states would increase model performance.* \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8DxXMVYi5DIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Answer:\n",
        "Q1_a =\"\" #@param {type :\"string\"}\n",
        "Q1_b =\"\" #@param {type :\"string\"}\n",
        "\n",
        "print(Q1_a)\n",
        "print(Q1_b)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UPbap8iqZxmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Click the play button to examine stock data\n",
        "import plotly.graph_objects as go\n",
        "def click_callback(trace, points, selector):\n",
        "    print(\"Click\")\n",
        "\n",
        "fig = go.Figure([go.Scatter(x=train_dat.index, y=np.log(train_dat['Close']))])\n",
        "#fig\n",
        "fig.data[0].on_click(click_callback)\n",
        "fig\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2B5NXsR5QX0_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter the number of states of the hidden feature in the form below\n",
        "\n",
        "b = 25 #number of bins\n",
        "\n",
        "s =  2 #@param {type:\"integer\"}\n",
        "\n",
        "Y = dat['Close']\n",
        "N = len(train_dat)\n",
        "\n",
        "df1 = np.log(Y) #log transformation of the closing price\n",
        "df2 = pd.cut(df1, bins = b, labels=range(0, b)) #bins df1 from 0 to b-1\n",
        "df3 = df1, df2\n",
        "\n",
        "log_close_binned = pd.concat(df3, axis = 1, keys = [\"LogPrice\", \"Bins\"])\n",
        "\n",
        "Y = [int(i) for i in list(df1)]\n",
        "Y_train = Y[:len(train_dat)]\n",
        "Y_test = Y[len(train_dat):]"
      ],
      "metadata": {
        "id": "-3D6WVzFwJ-e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 1 Based on the interactive plot above, can you estimate the dates on which your hidden state transitions occurred?\n",
        "---\n",
        "For example, if the estimated dates for these transitions are '2018-12-25', ' 2019-6-26', '2020-3-12', '2021-4-15', '2021-7-20', '2021-11-8', you would input \n",
        "\n",
        "1. The number of dates when transitions occured : 6\n",
        "2. The above dates without quotation marks or apostrophes: 2018-12-25, 2019-6-26, 2020-3-12, 2021-4-15, 2021-7-20, 2021-11-8\n",
        "\n",
        "If you need to set multiple dates, put a comma between the dates like such \n",
        "```2011-11-25, 2014-6-26```. Also, note that these dates must be in ascending order. \n",
        "\n"
      ],
      "metadata": {
        "id": "S7gCwXXFHnm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Provide the set of dates for transition in yyyy-mm-dd format\n",
        "\n",
        "num_dates = 6 #@param {type:\"integer\"}\n",
        "# dates = [pd.Timestamp(datetime(2018, 12, 15)), pd.Timestamp(datetime(2019, 7, 3)), pd.Timestamp(datetime(2020, 3, 14)), pd.Timestamp(datetime(2021, 4, 11)),\n",
        "#        pd.Timestamp(datetime(2021, 7, 20)), pd.Timestamp(datetime(2021, 11, 8))]\n",
        "date = \"2018-12-25, 2019-6-26, 2020-3-12, 2021-4-15, 2021-7-20, 2021-11-8\"#@param {type:\"string\"}\n",
        "date = date.split(',')\n",
        "format = \"%Y-%m-%d\"\n",
        "dates = [pd.to_datetime(item, format=format) for item in date]\n",
        "# dates = [pd.Timestamp(datetime(2018, 12, 15)), pd.Timestamp(datetime(2019, 6, 26)), pd.Timestamp(datetime(2020, 3, 12)), pd.Timestamp(datetime(2021, 4, 15)),\n",
        "#         pd.Timestamp(datetime(2021, 7, 20)), pd.Timestamp(datetime(2021, 11, 8))]\n",
        "\n",
        "# These dates have been set according to the start of the uptrend\n",
        "date_indices = []\n",
        "for i in dates:\n",
        "  for j in range(len(train_dat.index)):\n",
        "      if train_dat.index[j].date() == i.date():\n",
        "        date_indices.append(j)\n",
        "        break\n",
        "date_indices.append(0)\n",
        "date_indices.append(len(train_dat.index) - 1)\n",
        "date_indices.sort()\n",
        "print(date_indices)\n",
        "print(\"Input dates are the following:\", date)"
      ],
      "metadata": {
        "id": "teYbtDoIR1Nk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2: Specify these hidden state transitions and explain what each of these mean. \n",
        "> For example, if the estimated dates for these transitions are '2018-12-25', ' 2019-6-26' and the hidden states are (0,1,2) , and let us say on '2018-12-25' the transition occured from 0 to 2 and on '2019-6-26 the transition happened from 2 to 1 write it in the following manner: \n",
        "\n",
        "1. '2018-12-25': $ 0 \\to 2 $\n",
        "2. '2019-6-26': $2 \\to 1$\n",
        "\n",
        "We will use this information to setup the Guided Initialization. \n",
        "\n",
        "<em> Ans: </em> \n",
        "\n"
      ],
      "metadata": {
        "id": "m8IndEV8rB88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Forward Algorithms\n",
        "### Forward Pi iteration"
      ],
      "metadata": {
        "id": "x3hRcLO0U68V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward propagation.\n",
        "def ForwardpiZero(mu):\n",
        "    pi_zero = mu  \n",
        "    return pi_zero"
      ],
      "metadata": {
        "id": "S-rMIYH_UbJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Forwardpi(p,q,mu,N,Y):\n",
        "  '''\n",
        "  $\\rho_1, \\ldots \\rho_n \\in \\mathbb{R}^s$ where s := Number of hidden states\n",
        "\n",
        "  '''\n",
        "  pi = np.zeros((s,N)).reshape(s,N) # Initialization\n",
        "  rho = np.zeros((s, N))\n",
        "  a = np.zeros(N)\n",
        "  for x in range(s):\n",
        "    rho[x, 0] = np.sum([np.sum(mu[x_0, :]*p[x_0, x]*q[x, :, Y[0]]) for x_0 in range(s)])\n",
        "  a[0] = np.sum(rho[:, 0])\n",
        "  pi[:, 0] = rho[:, 0]/a[0]\n",
        "\n",
        "  for n in range(1, N):\n",
        "    rho[:, n] = q[:, Y[n-1], Y[n]]*(np.sum(pi[:, n - 1].reshape(s, 1)*p[:, :], axis = 0))\n",
        "    # print(rho.shape)\n",
        "    a[n] = np.sum(rho[:, n])  \n",
        "    pi[: ,n] = rho[:, n]/a[n]\n",
        "  return (pi, a, rho)"
      ],
      "metadata": {
        "id": "3CCbaBxB376e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Backward Iteration\n",
        "The backward algorithm is a function of the $a$, and $\\chi$ matrices. "
      ],
      "metadata": {
        "id": "Saet0bLpPuoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backward propagation.\n",
        "# Works only for s = 2. \n",
        "def Backwardchi(p,q,a,N,Y):\n",
        "    chi = np.zeros((s, N-1)).reshape(s,N-1)\n",
        "    chi[:, N - 2] = q[:, Y[N-2], Y[N-1]]\n",
        "\n",
        "    for n in range(N-3, -1, -1):\n",
        "      # print(n)\n",
        "      # print(np.sum((chi[:, n+1].reshape(1, s)*p[:, :]), axis = 1))\n",
        "      chi[:, n] = ((q[:, Y[n],Y[n+1]].reshape(s,1)/a[n+1]) *(np.sum((chi[:, n+1].reshape(1, s)*p[:, :]), axis = 1).reshape(s, 1))).reshape(s, )\n",
        "\n",
        "    return chi\n",
        "\n",
        "\n",
        "def BackwardchiZero(chi,p,q,a,N,Y):\n",
        "    chi_zero = np.zeros((s, b)).reshape(s,b)\n",
        "    for y in range(b):\n",
        "        chi_zero[:, y] = ((q[:, y, Y[0]].reshape(s, 1)/a[0]) *(np.sum((chi[:, 0].reshape(1, s)*p[:, :]), axis = 1).reshape(s, 1))).reshape(s, )\n",
        "        # chi_zero[0,y] = (q_zero[y,Y[0]]/a[0]) * (chi[0,0]*p[0,0]+ chi[1,0]*p[0,1])\n",
        "        # chi_zero[1,y] = (q_one[y,Y[0]]/a[0]) * (chi[0,0]*p[1,0]+ chi[1,0]*p[1,1])\n",
        "    \n",
        "    # chi_zero = normalize(chi_zero, axis = 0, norm = \"l1\")\n",
        "    return chi_zero\n"
      ],
      "metadata": {
        "id": "RTp-VHxPUfQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update Probabilities\n",
        "---\n",
        "Update probabilities:"
      ],
      "metadata": {
        "id": "uxmsDcZQUhmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now that we have all the elements for EM, start updating probabilities\n",
        "def MQ(p, pi_zero, pi, chi_zero, chi, N, Y):\n",
        "    q_new = np.zeros((s, b, b))\n",
        "    for y in range(b):\n",
        "        q_new[:, y, Y[0]] = (chi_zero[:, y].reshape(s, 1) * (np.sum(p[:, :]*pi_zero[:, y].reshape(s, 1), axis = 0).reshape(s, 1))).reshape(s,)\n",
        "    for n in range(N - 1):\n",
        "        q_new[:, Y[n], Y[n + 1]] = (q_new[:, Y[n], Y[n+1]].reshape(s, 1) + chi[:, n].reshape(s, 1) * (np.sum(p[:, :]*pi[:, n].reshape(s, 1), axis = 0).reshape(s, 1))).reshape(s, )\n",
        "    row_sum = q_new.sum(axis = 2)\n",
        "    for row in range(b):\n",
        "        for x in range(s):\n",
        "            if row_sum[x, row] != 0:\n",
        "                q_new[x, row, :] = q_new[x, row, :]/row_sum[x, row]\n",
        "\n",
        "    return q_new "
      ],
      "metadata": {
        "id": "EC3uKozPUptw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MMu(p,mu,chi_zero):\n",
        "    mu_new = np.zeros((s, b))\n",
        "    for y in range(b):\n",
        "        mu_new[:, y] = (mu[:, y].reshape(s, 1) * (p @ chi_zero[:, y].reshape(s, 1))).reshape(s,)\n",
        "        # mu_new[0,y] = mu[0,y]*(chi_zero[0,y]*p[0,0]+chi_zero[1,y]*p[0,1])\n",
        "        # mu_new[1,y] = mu[1,y]*(chi_zero[0,y]*p[1,0]+chi_zero[1,y]*p[1,1])\n",
        "        total = sum(list(mu_new.sum(axis=1)))\n",
        "    for i in range(s):   \n",
        "        for j in range(b):\n",
        "            if total != 0:\n",
        "                mu_new[i,j] = mu_new[i,j]/total\n",
        "            # else do nothing\n",
        "    #print(sum(list(mu_new.sum(axis=1))))\n",
        "    return mu_new"
      ],
      "metadata": {
        "id": "dHk8rHzIUs1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def MP(p, pi_zero, pi, chi_zero, chi):\n",
        "    p_old = p\n",
        "    p_new = np.zeros((s, s))\n",
        "    p_new = p_old * (pi_zero @ chi_zero.T + pi[:, :-1] @ chi.T) \n",
        "    row_sum = p_new.sum(axis = 1)\n",
        "    p_new = p_new/row_sum[:, np.newaxis]\n",
        "\n",
        "    return p_new\n"
      ],
      "metadata": {
        "id": "sCEMgalZUuNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the initial randomly generated estimates of $p$, $q_0$, $q_1$ and $μ$ needed for the EM algorithm.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Fscmh1j22KCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. Initializing the transition rates.\n",
        "\n",
        "In a Markov Observation Model, there are two transitions of interest: \n",
        "\n",
        "1. $P\\left(X_{n+1}=x \\mid Y_0=y_0, \\ldots, Y_n=y_n ; X_0=x_0, \\ldots, X_n=x_n\\right)=p_{x_n \\rightarrow x}$\n",
        "2. $P\\left(Y_{n+1}=y \\mid Y_0=y_0, \\ldots, Y_n=y_n ; X_0=x_0, X_n=x_n, X_{n+1}=x_{n+1}, \\ldots, X_N=x_N\\right)=q_{y_n \\rightarrow y}\\left(x_{n+1}\\right)$\n",
        "\n",
        "To get the estimates of these transition probabilities, we use the E.M. Algorithm. Starting from some initial values of these probabilities can be more fruitful than others. We can judge the best models using a quantitative measure such as the <b>Bayes Factor</b>. \n",
        "> *Definition* The Bayes factor is a measure of relative evidence, the comparison of the predictive performance of one model against another one. This comparison is a ratio of marginal likelihoods: $$ B F_{12}=\\frac{P\\left(\\boldsymbol{y} \\mid \\mathscr{M}_1\\right)}{P\\left(\\boldsymbol{y} \\mid \\mathscr{M}_2\\right)} $$\n",
        "$B F_{12} $ indicates the extent to which the data are more likely under $\\mathscr{M_1}$  over $\\mathscr{M_2}$ or in other words, which of the two models is more likely to have generated the data, or the relative evidence that we have for  $\\mathscr{M_1}$ over  $\\mathscr{M_2}$. [1] \n",
        "\n",
        "\n",
        "The higher the bayes factor, the better is your model (MOM) in comparison with the base model (The base model here being: $(X, Y)$ are independent Markov Chains).  Now that we have set up the foundations, the problem you would solve is the following: \n",
        "\n",
        "<blockquote> <b> <em> <u>Question</u> : </em> </b> For 10 models with random initializations, find the Bayes Factor of the best model. This is your best model out of the 10 random initializations. Report the best model and its Bayes Factor. Would you use this model in practice for predictions? Why or why not?\n",
        "Also report the best $P$, $Q$ and $\\mu$ matrices you finally get after running the programs. \n",
        "</blockquote>\n",
        "\n",
        "Answer: \n",
        "\n",
        "References: \n",
        "\n",
        "[1] https://vasishth.github.io/bayescogsci/book/ch-bf.html#bayes-factor"
      ],
      "metadata": {
        "id": "-m6fgr_aOV7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code for initial p, q, and mu matrix\n",
        "def InitialP(s):\n",
        "    p_v = []\n",
        "    for i in range(s):\n",
        "        p_r = np.random.uniform(0,1,s) #change 2 to some other number depending on the number of hidden states\n",
        "        p_r /= p_r.sum()\n",
        "        p_v.append(p_r)\n",
        "    p = np.array(p_v)\n",
        "    return p\n",
        "\n",
        "def InitialQ(N, Y, s: int):\n",
        "    q = np.zeros((s, b, b))\n",
        "    for x in range(s):\n",
        "        for n in range(N-1):\n",
        "          q[x, Y[n],Y[n+1]] += 1\n",
        "        row_sum = q.sum(axis=2)\n",
        "        print(row_sum.shape)\n",
        "        for row in range(b):\n",
        "          for coln in range(b):\n",
        "              if row_sum[x, row] > 0 and q[x, row, coln] > 0:\n",
        "                q[x, row,coln] = q[x, row,coln]*np.random.uniform(0,1,1)\n",
        "        row_sum_new = q.sum(axis=2)\n",
        "\n",
        "        for i in range(b):   \n",
        "          for j in range(b):\n",
        "            if row_sum_new[x, i] != 0:\n",
        "              q[x, i, j] = q[x, i, j]/row_sum_new[x, i] \n",
        "    return q  \n",
        "\n",
        "def Initialmu(q, Y):\n",
        "  '''\n",
        "  $\\mu \\in \\mathbb{R}^{s \\times b}$\n",
        "  where s := Number of hidden states\n",
        "  and N := Total observations\n",
        "  '''\n",
        "  mu = np.zeros((s, b))\n",
        "  print(mu.shape)\n",
        "  mu = np.random.rand(s, b)\n",
        "  for x in range(s):\n",
        "    for row in range(b):\n",
        "      if q[x, row, Y[0]] > 0:\n",
        "        continue \n",
        "      else: \n",
        "        mu[x, row] = 0\n",
        "  # for x in range(s): \n",
        "  #   for row in range(b): \n",
        "  #     if q[row,Y[0], x] > 0:\n",
        "  #       mu[x,row] = np.random.uniform(0,1,1)    \n",
        "  #     else:\n",
        "  #       mu[x,row] = 0\n",
        "\n",
        "  sum = mu.sum()\n",
        "  mu = mu/sum\n",
        "  return mu"
      ],
      "metadata": {
        "id": "j0aBJbmdb9CU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The forward algorithm is a function of the $\\pi$, $a$, and $\\rho$ matrices. "
      ],
      "metadata": {
        "id": "YhNrLP0r2fuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection \n",
        "$\\bar{q}_{i \\to j} = \\frac{\\text{#transitions from $i$ to $j$}}{\\text{#occurences of $i$}}$"
      ],
      "metadata": {
        "id": "RRfgzt3lzKYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Q_ref(Y, N):\n",
        "    q_bar = np.zeros((b, b))\n",
        "    for i in range(1, N):\n",
        "        q_bar[Y[i-1], Y[i]] += 1\n",
        "    row_sum = list(q_bar.sum(axis=1))\n",
        "    for row in range(b):\n",
        "        if row_sum[row] != 0:\n",
        "            q_bar[row] = q_bar[row]/row_sum[row]\n",
        "    return q_bar\n",
        "q_bar = Q_ref(Y, N)\n"
      ],
      "metadata": {
        "id": "rQKr4YxIy7k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Predictorlist(p, q, mu, q_bar, Y, N):\n",
        "    '''\n",
        "    \\rho_j(x_i) for all i \\in N in the MOMBF1 draft \n",
        "    is represented by predictor_dist[j - 1, i - 1]\n",
        "    The required number of rho's are N, since \\rho_{N} is the last predictor \n",
        "    Even though \\rho_{N} is the last predictor in the predictor sequence, \n",
        "    to compute the last Bayes factor we use \\rho_{N - 1}, \n",
        "    since only observed data is used for model comparison. \n",
        "    $\\rho_{N} provides the predicted distribution of \n",
        "    next hidden stated, given the observed data upto time $N$. \n",
        "    '''\n",
        "    predictor_dist = np.zeros((N, s))\n",
        "    temp = np.zeros(s)\n",
        "    for x in range(s):\n",
        "        # temp[x] = np.sum([np.sum(mu[x_0, :]*p[x_0, x]*np.where(q_bar[:, Y[0]] != 0, q[x, :, Y[0]]/q_bar[:, Y[0]], 0)) for x_0 in range(s)])\n",
        "        temp_ = np.array([(q[x, z, Y[0]]/q_bar[z, Y[0]] if q_bar[z, Y[0]] != 0 else 0) for z in range(b)])#np.where(q_bar[:, Y[0]] != 0, q[x, :, Y[0]]/q_bar[:, Y[0]], 0)\n",
        "        temp[x] = np.sum([np.sum(mu[x_0, :]*p[x_0, x]*temp_) for x_0 in range(s)])\n",
        "\n",
        "    for i in range(N):\n",
        "        for x in range(s):\n",
        "            if i == 0:\n",
        "                predictor_dist[0, x] = temp @ p[:, x]\n",
        "            else:\n",
        "                temp_ = q[:, Y[i - 1], Y[i]]/q_bar[Y[i - 1], Y[i]] if q_bar[Y[i - 1], Y[i]] != 0 else 0\n",
        "                predictor_dist[i, x] = np.sum(temp_ * p[:, x] * predictor_dist[i - 1, :])\n",
        "\n",
        "    return predictor_dist\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "def BayesFactor(predictor_rho, q, N, Y):\n",
        "    B = np.zeros(N)\n",
        "    for i in range(N):\n",
        "        B[i] = np.sum(predictor_rho[i, :])\n",
        "    # print(B[-1])\n",
        "    B[-1] = np.sum([((predictor_rho[N-2, x] * q[x, Y[-2], Y[-1]]/q_bar[Y[-2], Y[-1]]) if q_bar[Y[-2], Y[-1]] != 0 else 0) for x in range(s)])\n",
        "    # print(B[-1])\n",
        "    return B"
      ],
      "metadata": {
        "id": "lezyEr1x8AYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Iteration until convergence:"
      ],
      "metadata": {
        "id": "0yj1fl-sP7PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Stop(p_new ,mu_new, q_new, p, mu, q, k):\n",
        "\n",
        "    #print(k)\n",
        "\n",
        "    p_new = p_new\n",
        "    p = p\n",
        "    difp = np.subtract(p_new, p)\n",
        "    sdifp = np.nansum(np.abs(difp))\n",
        "\n",
        "    q = q\n",
        "    q_new = q_new\n",
        "    mu_new = mu_new\n",
        "    mu = mu\n",
        "    difmu = np.subtract(mu_new, mu)\n",
        "    sdifmu = np.nansum(np.abs(difmu))\n",
        "\n",
        "    np.set_printoptions(suppress=True)\n",
        "\n",
        "    if sdifp < 5e-3 and sdifmu < 5e-3:\n",
        "        # print(\"Penultimate p matrix: \", p)\n",
        "        # print(\"Final p matrix: \", p_new)\n",
        "        # print(\"Final mu matrix: \", mu)\n",
        "        return 'stop'\n",
        "\n",
        "    else:\n",
        "        return 'continue'"
      ],
      "metadata": {
        "id": "OOL88R0fP6WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RunModel(p, q, mu, N, Y, stoplimit = 1000):\n",
        "    K = stoplimit\n",
        "    for k in range(K):\n",
        "        pi_zero = ForwardpiZero(mu)\n",
        "        pi, a, rho = Forwardpi(p,q,mu,N,Y)\n",
        "  \n",
        "  # a_1, a_n = aMatrix(p,q_zero,q_one,mu,pi,N,Y)\n",
        "\n",
        "        chi = Backwardchi(p,q, a,N,Y)\n",
        "        chi_zero = BackwardchiZero(chi,p,q,a,N,Y)\n",
        "\n",
        "  # q_zero_new = MQZero(p, pi_zero, pi, chi_zero, chi,N,Y)\n",
        "  # q_one_new = MQOne(p, pi_zero, pi, chi_zero, chi, N, Y)\n",
        "        q_new = MQ(p, pi_zero, pi, chi_zero, chi, N, Y)\n",
        "        mu_new = MMu(p, mu, chi_zero)\n",
        "        p_new = MP(p, pi_zero, pi, chi_zero, chi)\n",
        "\n",
        "        stopcondition = Stop(p_new,mu_new,q_new, p, mu, q, k)\n",
        "\n",
        "        if stopcondition == \"stop\":\n",
        "            print(\"Stopping criteria reached at k = \", k)\n",
        "            break\n",
        "        else:\n",
        "            p = p_new\n",
        "            mu = mu_new\n",
        "            q = q_new\n",
        "    \n",
        "    return (p, q, mu)\n",
        "\n"
      ],
      "metadata": {
        "id": "QhfCp-3-Uwmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model selection using bayes factor\n",
        "We intend to select a model which has the highest Bayes Factor. To do this, we initialize with various $P$, $Q$ and $\\mu$ matrices and then sort the models according to their bayes factors. Play around with the number of particles to This might take some time to execute. "
      ],
      "metadata": {
        "id": "d7IMOxZCALgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the code for 10 models\n",
        "num_particles = 10 \n",
        "model_initializations = {}\n",
        "model_results = {}\n",
        "comparison_dict = {}\n",
        "for i in range(1, num_particles + 1):\n",
        "    model_name = f\"model{i}\"\n",
        "    \n",
        "    model_initializations[model_name] = {}\n",
        "    model_initializations[model_name]['P'] = InitialP(s)\n",
        "    model_initializations[model_name]['Q'] = InitialQ(N, Y_train, s)\n",
        "    model_initializations[model_name]['mu'] = Initialmu(model_initializations[model_name]['Q'], Y_train)\n",
        "    \n",
        "    FinalP, FinalQ, Finalmu = RunModel(model_initializations[model_name]['P'], model_initializations[model_name]['Q'], model_initializations[model_name]['mu'], N, Y_train)\n",
        "    Predictor = Predictorlist(FinalP, FinalQ, Finalmu, q_bar, Y_train, N)\n",
        "    comparison_dict[model_name] = np.log(BayesFactor(Predictor, FinalQ, N, Y_train)[-1]) # Take log of the Bayes Factor, since it expands exponentially. \n",
        "\n",
        "    model_results[model_name] = {}\n",
        "    model_results[model_name]['P'] = FinalP\n",
        "    model_results[model_name]['Q'] = FinalQ\n",
        "    model_results[model_name]['mu'] = Finalmu"
      ],
      "metadata": {
        "id": "irYlXf3FALR1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the code to check the best model result!\n",
        "sorted_by_bf = sorted(comparison_dict.items(), key = lambda x: x[1])\n",
        "print(\"The models and (log of) Bayes factor are displayed in Ascending order\")\n",
        "print(sorted_by_bf)\n",
        "best_model = sorted_by_bf[-1]\n",
        "best_model_results = model_results[best_model[0]]\n",
        "print(\"Model with the highest Bayes Factor: \", best_model[0])\n",
        "print(\"Bayes Factor of the best model: \", best_model[1])\n",
        "print(best_model_results)"
      ],
      "metadata": {
        "id": "rt15RlZzNzrV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Setup 2: Guided Initialization\n",
        "---\n",
        "In the last question, we tried to find out the best initialized model by comparing it with their Bayes Factor. Now let us try to give the model a guided initialized. The term guided initialization implies that setting up the initial probabilities in such a way, such that the model picks up features as per your design.\n",
        "<blockquote> <em> (Example: Uptrends and Downtrends) </em> Let's say we wanted to recover uptrends and downtrends (uptrend is denoted by $1$ and downtrend is denoted by $0$) from the observed data (i.e. stock price of BTC). For this scenario, the total number of hidden states would be 2 (i.e. <em> s = 2 </em> ). Moreover, let's say if we assumed that if the current hidden state is uptrend, then the hidden state stays in an uptrend state on an average of 49 days. On the other hand, if the current hidden state is downtrend, then the hidden state stays in downtrend on an average of 19 days. If we believe that such an assumption was close to the truth, then we can initialize the parameter $p$ as follows: \n",
        "$$\n",
        "    p = \\left[\\begin{array}{l}p_{0 \\rightarrow 0} p_{0 \\rightarrow 1} \\\\ p_{1 \\rightarrow 0} p_{1 \\rightarrow 1}\\end{array}\\right]=\\left[\\begin{array}{l}0.95 & 0.05 \\\\ 0.02 &0.98 \\end{array}\\right]\n",
        "$$\n",
        "\n",
        "</blockquote>\n",
        "Now, if we were to design a transition matrix $p$ according to different interpretation of hidden states, what would the initial transition matrix look like? \n",
        "<blockquote> \n",
        "Design the initial transition matrix $p$ according to your previously described interpretation of the hidden state. \n",
        "\n",
        "To enter a matrix as input, follow this convention:\n",
        "$$\n",
        "[[p_{00}, p_{01}, \\ldots, p_{0n}], [p_{10}, \\ldots, p_{1n}], \\ldots, [p_{n0}, \\ldots, p_{nn}]]\n",
        "$$\n"
      ],
      "metadata": {
        "id": "T3K5mQtWx9n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Guided Initialization (Enter your designed $p$ matrix here [use the convention above])\n",
        "def GuidedInitialP(s):\n",
        "#  p = np.array([[0.98, 0.02], [0.04, 0.96]])\n",
        "  # p = np.array([[0.9, 0.1], [0.01, 0.99]])\n",
        "  # p = np.array([[0.997, 0.003], [0.003, 0.997]])\n",
        "    p = [[0.95, 0.05], [0.02, 0.98]] #@param\n",
        "    p = np.array(p)\n",
        "    if p.shape != (s, s):\n",
        "        raise Exception(\"The dimension of p doesn't match the number of hidden states\")\n",
        "    return p\n",
        "\n",
        "guided_initialization = {}\n",
        "guided_model_results = {}\n",
        "\n",
        "guided_initialization['P'] = GuidedInitialP(s)\n",
        "guided_initialization['Q'] = InitialQ(N, Y_train, s)\n",
        "guided_initialization['mu'] = Initialmu(guided_initialization['Q'], Y_train)\n",
        "\n",
        "FinalP, FinalQ, Finalmu = RunModel(guided_initialization['P'], guided_initialization['Q'], guided_initialization['mu'], N, Y_train)\n",
        "Predictor = Predictorlist(FinalP, FinalQ, Finalmu, q_bar, Y_train, N)\n",
        "# Take log of the Bayes Factor, since it expands exponentially. \n",
        "\n",
        "guided_model_results['P'] = FinalP\n",
        "guided_model_results['Q'] = FinalQ\n",
        "guided_model_results['mu'] = Finalmu\n",
        "\n",
        "print(guided_model_results)"
      ],
      "metadata": {
        "id": "mZq0ihycLnEH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4: Evaluating the Bayes factor and comparing it with the best model out of 10 models\n",
        "\n",
        "> Evaluate the Bayes Factor of the Guided Model and compare it with the best model generated using random initializations. If the Bayes factor of the Guided Model is higher than that of the best of random models, the guided assumption is closer to the truth. You would notice that as you increase the number of hidden states, the Bayes Factor improves as well. Why do you think that is? \n",
        "\n",
        "Answer: \n"
      ],
      "metadata": {
        "id": "asgDUt437u-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GM_Predictor = Predictorlist(guided_model_results['P'], guided_model_results['Q'], guided_model_results['mu'], q_bar, Y, N)\n",
        "GM_BF = np.log(BayesFactor(GM_Predictor, guided_model_results['Q'], N, Y)[-1])\n",
        "print(GM_BF)"
      ],
      "metadata": {
        "id": "cwsdCrkkDlgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 3: Printing Output of the Most Likely Sequence\n",
        "\n",
        "After recovering the Final $P, Q \\, \\text{and} \\, \\mu$ matrices, we would like to recover the most likely sequence of hidden states. You can see the most likely sequence of hidden states for either the `best model` or the `guided model`. "
      ],
      "metadata": {
        "id": "h8SDjtFiVyTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Most Likely Sequence!\n",
        "---\n",
        "**Viterbi algorithm**:\n",
        "\n",
        "Using the updated transition matrices from our EM, we can implement the special case of the Viterbi algorithm for MOM. \n",
        "\n"
      ],
      "metadata": {
        "id": "EkkbeAqeQEUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input: Observational sequence $Y_1, \\dots, Y_N$\n",
        "Output: Most likely hidden state sequence: $P*; y_0*; x_0*, x_1*, \\dots, x_N*$\n",
        "Data: Transition probability matrices from EM ($P, Q_s, \\mu$)."
      ],
      "metadata": {
        "id": "mVfJl3_pWOsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DeltaZero(p_new, q_new, mu_new):\n",
        "  delta_01 = np.zeros((b,s,s)).reshape(b,s,s)\n",
        "  for row in range(b):\n",
        "    # delta_01[row,0,0] = mu_new[0,row]*p_new[0,0]*q_zero_new[row,Y[0]]\n",
        "    # delta_01[row,0,1] = mu_new[0,row]*p_new[0,1]*q_one_new[row,Y[0]]\n",
        "    # delta_01[row,1,0] = mu_new[1,row]*p_new[1,0]*q_zero_new[row,Y[0]]\n",
        "    # delta_01[row,1,1] = mu_new[1,row]*p_new[1,1]*q_one_new[row,Y[0]]\n",
        "    delta_01[row, :, :] = (mu_new[:, row].reshape(s, 1) @ q_new[:, row, Y[0]].reshape(1, s)) * p_new\n",
        "\n",
        "  #delta_01[delta_01 < 1E-308] = 0\n",
        "\n",
        "  return delta_01\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XndKjdj5WmWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward from $n:= 3$ to $N$"
      ],
      "metadata": {
        "id": "6IubQTz_WrmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Delta(p_new, q_new, mu_new, delta_01):\n",
        "  #for n = 1\n",
        "  delta = np.zeros((N,s)).reshape(N,s)\n",
        "  delta[0] = np.sum(np.sum(delta_01, axis = 0),axis = 0)\n",
        "  # #for n = 2\n",
        "  # delta[1,0] = max(max(delta_01[:,0,0]*p_new[0,0]), max(delta_01[:,1,0]*p_new[1,0]))*q_new[0, Y[0],Y[1]]\n",
        "  # delta[1,1] = max(max(delta_01[:,0,1]*p_new[0,1]), max(delta_01[:,1,1]*p_new[1,1]))*q_new[1, Y[0],Y[1]]\n",
        "\n",
        "  # delta[1,0] = delta[1,0] / sum(delta[1,:])\n",
        "  # delta[1,1] = delta[1,1]/sum(delta[1,:])\n",
        "\n",
        "  # for x in range(s):\n",
        "  #   delta[1, x] = np.max(np.amax(delta_01[:, :, x], axis = 0) * p[:, x].reshape(s, 1))*q_new[x, Y[0], Y[1]]\n",
        "  delta[1, :] = np.amax(np.amax(delta_01[:, :, :] * p_new.reshape(1, s, s), axis = 0), axis = 0)*q_new[:, Y[0], Y[1]]\n",
        "\n",
        "  delta[1,:] = delta[1,:] / np.sum(delta[1,:])\n",
        "  \n",
        "  #for n: =3 to N\n",
        "  for n in range(2,N): #n = 2,...N-1\n",
        "\n",
        "    delta[n, :] = np.amax(delta[n-1, :].reshape(s, 1) * p_new, axis = 0)*q_new[:, Y[n-1], Y[n]]\n",
        "    # print(np.amax(delta[n-1, :].reshape(s, 1) * p_new, axis = 0))\n",
        "    # print(max(delta[n-1,0]*p_new[0,0], delta[n-1,1]*p_new[1,0]), max(delta[n-1,0]*p_new[0,1],delta[n-1,1]*p_new[1,1]))\n",
        "    # delta[n,0] = max(delta[n-1,0]*p_new[0,0], delta[n-1,1]*p_new[1,0])*q_new[0, Y[n-1],Y[n]]\n",
        "    # delta[n,1] = max(delta[n-1,0]*p_new[0,1],delta[n-1,1]*p_new[1,1])*q_new[1, Y[n-1],Y[n]]\n",
        "\n",
        "    delta[n,:] = delta[n,:] / sum(delta[n,:])\n",
        "    # delta[n,0] = delta[n,0] / sum(delta[n,:])\n",
        "    # delta[n,1] = delta[n,1] / sum(delta[n,:])\n",
        "  \n",
        "\n",
        "  \n",
        "  return delta"
      ],
      "metadata": {
        "id": "wB-lFakxEMzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backtracing $N-1$ down to 2"
      ],
      "metadata": {
        "id": "ZlkEVad7W38B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Psi(p_new, delta_01, delta):\n",
        "  #psi start from n = 2\n",
        "  psi = np.zeros((N-1,s)).reshape(N-1,s)\n",
        "  psi[0, :] = np.argmax(np.amax(delta_01[:, :, :] * p_new.reshape(1, s, s), axis = 0), axis = 0)\n",
        "  # psi[0,0] = np.argmax(np.array([max(delta_01[:,0,0]*p_new[0,0]), max(delta_01[:,1,0]*p_new[1,0])]))\n",
        "  # psi[0,1] = np.argmax(np.array([max(delta_01[:,0,1]*p_new[0,1]), max(delta_01[:,1,1]*p_new[1,1])]))\n",
        "\n",
        "  for n in range(2,N):\n",
        "    psi[n-1 :] = np.argmax(delta[n-1, :].reshape(s, 1) * p_new, axis = 0)\n",
        "    # psi[n-1,0] = np.argmax(np.array([delta[n-1,0]*p_new[0,0], delta[n-1,1]*p_new[1,0]]))\n",
        "    # psi[n-1,1] = np.argmax(np.array([delta[n-1,0]*p_new[0,1],delta[n-1,1]*p_new[1,1]]))\n",
        "\n",
        "  return psi\n",
        "\n",
        "def Termination(delta):\n",
        "  P = max(delta[N-1,:])\n",
        "  x_N = np.argmax([delta[N-1,:]])\n",
        "\n",
        "  return P, x_N\n",
        "\n",
        "def BackTracking(psi, x_N):\n",
        "  x_n = np.zeros((N-1,1)).reshape(N-1,1)\n",
        "  #x_n's size is (1461,1), psi's size is (1461, 2). need to fix this\n",
        "  x_n[N-2] = psi[N-2, x_N]\n",
        "  for i in range(N-3, 0, -1): # include index N-2 and i\n",
        "     x_n[i] = psi[i+1, int(x_n[i+1])]\n",
        "\n",
        "  return x_n"
      ],
      "metadata": {
        "id": "45H5DF0WWvNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def print_results(model_results, data):\n",
        "\n",
        "    p, q, mu = model_results['P'], model_results['Q'], model_results['mu']\n",
        "\n",
        "    delta_01 = DeltaZero(p, q, mu)\n",
        "    delta = Delta(p, q, mu, delta_01)\n",
        "\n",
        "    psi = Psi(p, delta_01, delta)\n",
        "    P, x_N = Termination(delta)\n",
        "\n",
        "\n",
        "    out = BackTracking(psi, x_N)\n",
        "    fig, ax = plt.subplots()\n",
        "    axes = [ax, ax.twinx()]\n",
        "    colors = ['blue', 'orange']\n",
        "    fig.suptitle('Plots of likely states and log price')\n",
        "\n",
        "    axes[0].plot(1*out[0:len(data)], alpha = 0.75, label=\"Likely State\", color='blue')\n",
        "    axes[1].plot(range(len(data)),df1[0:len(data)], label = \"Log Price\", color='orange')\n",
        "    axes[0].set_ylabel(\"Hidden State\")\n",
        "    axes[1].set_ylabel(\"Log Price of Bitcoin\")\n",
        "    # plt.plot(range(1000), 8.0 + 3.5*pi_n[1, :1000], alpha = 0.25)\n",
        "    fig.legend()\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "iQgZr6jPc7L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting output for the most likely hidden state"
      ],
      "metadata": {
        "id": "vrD2NUlkXCdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print plots of the likely hidden state sequence and the log price\n",
        "model_results = best_model_results #@param [\"best_model_results\", \"guided_model_results\"] {type:\"raw\"}\n",
        "print_results(model_results, train_dat) \n"
      ],
      "metadata": {
        "id": "EJefL5IKeCXX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Q5: Test your hypothesis for the guided model by looking at the most likely hidden state sequence\n",
        "\n",
        "<blockquote> <em> <b> (Question) </b> </em> Look at the plot of most likely hidden state sequence. Try to verify the model's interpretation of the hidden state as compared to your interpretation of it. \n",
        "\n",
        "</blockquote> \n",
        "\n",
        "<blockquote> \n",
        "Moreover, according to you, what does the hidden state of the best random model represent? Does the hidden state sequence for the guided model capture the desired features? \n",
        "</blockquote>\n",
        "\n",
        "Answer: \n",
        " "
      ],
      "metadata": {
        "id": "_PuiH9ZZv6WK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup 4: Employ a strategy to make money using limited transactions\n",
        "When would you exercise your transactions? We would like to emulate this using a real-life scenario, considering your only know the stock's history upto the current time. How would you use your current states to make money? The only caveat being, only a single amount of the stock can be bought or sold.  \n",
        "\n",
        "<!-- For maximum profit: https://www.geeksforgeeks.org/maximum-profit-by-buying-and-selling-a-share-at-most-k-times/ -->\n",
        "\n",
        "<!-- <b> Hint: Use the 1-step predictor </b>  -->\n",
        "\n",
        "Let's say $\\alpha \\in (0, 1)$ represents your risk index. The more risk you are willing to take, you would not wait for the stock to go too high/low before selling/buying the stock. Let's say you are at the hidden state $X_{current}$ and you would like to exercise the transaction (buy/sell) when you reach a particular hidden state $X_{desired}$, when you would exercise the transactions. \n",
        "\n",
        "*Hint*: You are willing to sell your stock, if you are in certain transition states while you would buy in others. \n",
        "<br>\n",
        "### <em> Rules of the Game: \n",
        "<blockquote> Assume you start with 1 stock and you can either hold it or sell it but you <u> can not buy or hold more than 1 stock at a single point of time</u>. If you sell the held stock, you now have room to buy 1 more stock. You can buy or sell <u> upto 10 times </u>.  \n",
        "</blockquote> </em>\n",
        "\n",
        "Employ the hidden states you designed to construct a strategy that would help you make money from the test set (The test set is the future trajectory of the Bitcoin price).\n"
      ],
      "metadata": {
        "id": "dKS0ChM55yTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setting parameters for the test set\n",
        "N_test = len(Y_test) \n",
        "num_transactions = 10\n",
        "alpha = 0.25 #@param {type:\"number\"}\n",
        "buy_transitions = [1] #@param #if the stock is increasing\n",
        "sell_transitions = [0] #@param #if the stock is decreasing\n",
        "Model = best_model_results #@param [\"best_model_results\", \"guided_model_results\"] {type:\"raw\"}\n",
        "# if past_action = 0, not yet invested\n",
        "# if past_action = 1, bought \n",
        "# if past_action = -1, sold"
      ],
      "metadata": {
        "id": "qZLwXdsVd7Qf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Playing the Game! Did you make a profit or loss? \n",
        "OnestepPreds = Predictorlist(Model['P'], Model['Q'], Model['mu'], q_bar, Y_test, N_test)\n",
        "PredProbs = OnestepPreds/np.sum(OnestepPreds, axis = 1).reshape(N_test, 1)\n",
        "past_action = 1\n",
        "possible_action = -1 * past_action\n",
        "profit = 0 \n",
        "\n",
        "exec_transactions = 0\n",
        "threshold = 1 - alpha \n",
        "past_price = test_dat['Close'][0]\n",
        "print(\"Initial Price of 1 bitcoin:\", past_price)\n",
        "for i in range(len(OnestepPreds)):\n",
        "    if exec_transactions >= 10:\n",
        "        break\n",
        "    if past_action == 1:\n",
        "        for item in sell_transitions:\n",
        "            if PredProbs[i][item] > threshold:\n",
        "                past_action = -1\n",
        "                profit += test_dat['Close'][i + 1] - past_price\n",
        "                # print(profit)\n",
        "                past_price = 0\n",
        "                exec_transactions += 1\n",
        "                print(\"1 Bitcoin was sold at a price of:\", test_dat['Close'][i + 1])\n",
        "                break \n",
        "            else:\n",
        "                continue\n",
        "    elif past_action == -1: \n",
        "        for item in buy_transitions:\n",
        "            if PredProbs[i][item] > threshold:\n",
        "                past_action = 1\n",
        "                past_price = test_dat['Close'][i + 1]\n",
        "                exec_transactions += 1\n",
        "                print(\"1 Bitcoin was bought at price: \", past_price)\n",
        "                break\n",
        "            else:\n",
        "                continue\n",
        "        \n",
        "if profit < 0: \n",
        "    print(\"You incurred a loss of: $\", -profit)\n",
        "else:\n",
        "    print(\"You profited: $\", profit)"
      ],
      "metadata": {
        "id": "NJSpBwtGlyU1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6: Explain your strategy to make money\n",
        "\n",
        "> ***(Question)*** Explain how you used the hidden states to make a decision to buy or sell Bitcoin? What more information could you use to make a better decision (Not necessarily related to the Markov Observation Model paradigm)? \n",
        "\n",
        "Answer: "
      ],
      "metadata": {
        "id": "PZb6yu2JB9Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZ0KHXw4P7Of"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}